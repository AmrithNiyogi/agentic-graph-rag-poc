{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59920e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bed0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-CABR9YsUh5yNXtptYSFvhPN8N8q28\",\n",
      "  \"created\": 1756543279,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_80956533cb\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Yes, I'm ready! How can I assist you today?\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": null,\n",
      "        \"function_call\": null,\n",
      "        \"annotations\": []\n",
      "      },\n",
      "      \"provider_specific_fields\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 13,\n",
      "    \"prompt_tokens\": 27,\n",
      "    \"total_tokens\": 40,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"service_tier\": \"default\"\n",
      "}\n",
      "\n",
      "OpenAI is ready for use.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Defining Model Constants for easier use \n",
    "MODEL_GPT = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "response = llm.llm_client.completion(\n",
    "    model=llm.model,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}],\n",
    "    tools=[]\n",
    ")\n",
    "print(json.dumps(response.dict(), indent=2))\n",
    "\n",
    "print(\"\\nOpenAI is ready for use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3e5f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n"
     ]
    }
   ],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c86e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_role_and_goal = \"\"\"\n",
    "  You are a top-tier algorithm designed for analyzing text files and proposing\n",
    "  the kind of named entities that could be extracted which would be relevant \n",
    "  for a user's goal.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c382f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_hints = \"\"\"\n",
    "  Entities are people, places, things and qualities, but not quantities. \n",
    "  Your goal is to propose a list of the type of entities, not the actual instances\n",
    "  of entities.\n",
    "\n",
    "  There are two general approaches to identifying types of entities:\n",
    "  - well-known entities: these closely correlate with approved node labels in an existing graph schema\n",
    "  - discovered entities: these may not exist in the graph schema, but appear consistently in the source text\n",
    "\n",
    "  Design rules for well-known entities:\n",
    "  - always use existing well-known entity types. For example, if there is a well-known type \"Person\", and people appear in the text, then propose \"Person\" as the type of entity.\n",
    "  - prefer reusing existing entity types rather than creating new ones\n",
    "  \n",
    "  Design rules for discovered entities:\n",
    "  - discovered entities are consistently mentioned in the text and are highly relevant to the user's goal\n",
    "  - always look for entities that would provide more depth or breadth to the existing graph\n",
    "  - for example, if the user goal is to represent social communities and the graph has \"Person\" nodes, look through the text to discover entities that are relevant like \"Hobby\" or \"Event\"\n",
    "  - avoid quantitative types that may be better represented as a property on an existing entity or relationship.\n",
    "  - for example, do not propose \"Age\" as a type of entity. That is better represented as an additional property \"age\" on a \"Person\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297f641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_chain_of_thought_directions = \"\"\"\n",
    "  Prepare for the task:\n",
    "  - use the 'get_user_goal' tool to get the user goal\n",
    "  - use the 'get_approved_files' tool to get the list of approved files\n",
    "  - use the 'get_well_known_types' tool to get the approved node labels\n",
    "\n",
    "  Think step by step:\n",
    "  1. Sample some of the files using the 'sample_file' tool to understand the content\n",
    "  2. Consider what well-known entities are mentioned in the text\n",
    "  3. Discover entities that are frequently mentioned in the text that support the user's goal\n",
    "  4. Use the 'set_proposed_entities' tool to save the list of well-known and discovered entity types\n",
    "  5. Use the 'get_proposed_entities' tool to retrieve the proposed entities and present them to the user for their approval\n",
    "  6. If the user approves, use the 'approve_proposed_entities' tool to finalize the entity types\n",
    "  7. If the user does not approve, consider their feedback and iterate on the proposal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130b948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_instruction = f\"\"\"\n",
    "{ner_agent_role_and_goal}\n",
    "{ner_agent_hints}\n",
    "{ner_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "#print(ner_agent_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea7b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools to propose and approve entity types\n",
    "PROPOSED_ENTITIES = \"proposed_entity_types\"\n",
    "APPROVED_ENTITIES = \"approved_entity_types\"\n",
    "\n",
    "def set_proposed_entities(proposed_entity_types: list[str], tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Sets the list proposed entity types to extract from unstructured text.\"\"\"\n",
    "    tool_context.state[PROPOSED_ENTITIES] = proposed_entity_types\n",
    "    return tool_success(PROPOSED_ENTITIES, proposed_entity_types)\n",
    "\n",
    "def get_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the list of proposed entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_ENTITIES, [])\n",
    "\n",
    "def approve_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon approval from user, records the proposed entity types as an approved list of entity types \n",
    "\n",
    "    Only call this tool if the user has explicitly approved the suggested files.\n",
    "    \"\"\"\n",
    "    if PROPOSED_ENTITIES not in tool_context.state:\n",
    "        return tool_error(\"No proposed entity types to approve. Please set proposed entities first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_ENTITIES] = tool_context.state.get(PROPOSED_ENTITIES)\n",
    "    return tool_success(APPROVED_ENTITIES, tool_context.state[APPROVED_ENTITIES])\n",
    "\n",
    "def get_approved_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the approved list of entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(APPROVED_ENTITIES, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0d9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_well_known_types(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the approved labels that represent well-known entity types in the graph schema.\"\"\"\n",
    "    construction_plan = tool_context.state.get(\"approved_construction_plan\", {})\n",
    "    # approved labels are the keys for each construction plan entry where `construction_type` is \"node\"\n",
    "    approved_labels = {entry[\"label\"] for entry in construction_plan.values() if entry[\"construction_type\"] == \"node\"}\n",
    "    return tool_success(\"approved_labels\", approved_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ebc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "from helper import get_neo4j_import_dir\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "\n",
    "def get_approved_user_goal(tool_context: ToolContext):\n",
    "    \"\"\"Returns the approved user goal from the tool context state, if it exists.\"\"\"\n",
    "    APPROVED_USER_GOAL = \"approved_user_goal\"\n",
    "    if APPROVED_USER_GOAL not in tool_context.state:\n",
    "        return tool_error(\"No approved user goal found. Approve a user goal first.\")\n",
    "    return tool_success(APPROVED_USER_GOAL, tool_context.state[APPROVED_USER_GOAL])\n",
    "\n",
    "def sample_file(file_path: str, tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Samples a file by reading its content as text.\n",
    "    \n",
    "    Treats any file as text and reads up to a maximum of 100 lines.\n",
    "    \n",
    "    Args:\n",
    "      file_path: file to sample, relative to the import directory\n",
    "      \n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content,\n",
    "            along with a sampling of the file.\n",
    "            Includes a 'status' key ('success' or 'error').\n",
    "            If 'success', includes a 'content' key with textual file content.\n",
    "            If 'error', includes an 'error_message' key.\n",
    "            The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # Trust, but verify. The agent may invent absolute file paths. \n",
    "    if Path(file_path).is_absolute():\n",
    "        return tool_error(\"File path must be relative to the import directory. Make sure the file is from the list of available files.\")\n",
    "    \n",
    "    import_dir = Path(get_neo4j_import_dir())\n",
    "\n",
    "    # create the full path by extending from the import_dir\n",
    "    full_path_to_file = import_dir / file_path\n",
    "    \n",
    "    # of course, _that_ may not exist\n",
    "    if not full_path_to_file.exists():\n",
    "        return tool_error(f\"File does not exist in import directory. Make sure {file_path} is from the list of available files.\")\n",
    "    \n",
    "    try:\n",
    "        # Treat all files as text\n",
    "        with open(full_path_to_file, 'r', encoding='utf-8') as file:\n",
    "            # Read up to 100 lines\n",
    "            lines = list(islice(file, 100))\n",
    "            content = ''.join(lines)\n",
    "            return tool_success(\"content\", content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return tool_error(f\"Error reading or processing file {file_path}: {e}\")\n",
    "    \n",
    "# Tool: Get Approved Files\n",
    "def get_approved_files(tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Returns the approved files from the tool context state, if they exist.\"\"\"\n",
    "    APPROVED_FILES = \"approved_files\"\n",
    "    if APPROVED_FILES not in tool_context.state:\n",
    "        return tool_error(\"No approved files found. Approve suggested files first.\")\n",
    "    return tool_success(APPROVED_FILES, tool_context.state[APPROVED_FILES])\n",
    "\n",
    "ner_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, sample_file,\n",
    "    get_well_known_types,\n",
    "    set_proposed_entities,\n",
    "    approve_proposed_entities\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daff0f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/csv_files\n",
      "{'status': 'success', 'content': \"# Gothenburg Table Reviews\\n\\nScraped from https://www.between2furns.com/Gothenburg-Table/dp/B0BQJWJWJW\\n\\n## Rating: ★★★★★ (5/5)\\nThis table is the centerpiece of our dining room! The modern design is stunning yet timeless, and the quality is exceptional. We've had it for 6 months now and it still looks brand new despite daily use with two kids. Assembly took about an hour with two people. The surface is easy to clean and surprisingly resistant to scratches. Highly recommend!\\n\\n- @akollegger (Cambridge)\\n\\n---\\n\\n## Rating: ★★★☆☆ (3/5)\\nThe Gothenburg Table looks beautiful, I'll give it that. But assembly was a nightmare - some of the pre-drilled holes didn't line up properly and I had to drill new ones. Once assembled, it's sturdy enough, but I expected better quality control for this price point. The table top also shows fingerprints very easily which is annoying for daily use.\\n\\n- @furniture_lover92 (Seattle)\\n\\n---\\n\\n## Rating: ★★★★☆ (4/5)\\nlove love LOVE the look of this table!! perfect size for my apartment and the finish is gorgeous. took off a star because it was kinda complicated to put together and the instructions were confusing. but now that it's built it's perfect and all my friends are jealous. definitely worth the struggle lol\\n\\n- @designer_dave (Portland)\\n\\n---\\n\\n## Rating: ★★★★★ (5/5)\\nAs someone who entertains frequently, I needed a table that was both functional and aesthetically pleasing. The Gothenburg Table delivers on both counts. The dimensions (180cm x 90cm) are perfect for seating 6-8 people comfortably. The solid wood construction gives it a substantial feel, and the joinery is impeccable. The finish has a subtle matte quality that highlights the natural grain patterns. Assembly was straightforward with clear instructions. This table will clearly last for decades.\\n\\n- @home_chef (Chicago)\\n\\n---\\n\\n## Rating: ★★☆☆☆ (2/5)\\nDisappointed with this purchase. The table arrived with a small dent on one edge, and while customer service was helpful in sending a replacement part, it was a hassle to deal with. The table also wobbles slightly on my hardwood floor despite multiple attempts to adjust it. For the price, I expected better quality control.\\n\\n- @diydan (Austin)\\n\\n---\\n\\n## Rating: ★★★★★ (5/5)\\nPerfect table for our family of four! We've been using it daily for meals, homework, and game nights for the past year. It's held up beautifully with no signs of wear. The surface cleans easily and has resisted stains from art projects and spilled drinks. Assembly was straightforward and the included tools were adequate. The design is simple yet elegant - exactly what we wanted.\\n\\n- @familyfirst (Denver)\\n\\n---\\n\\n## Rating: ★★★★☆ (4/5)\\nGood quality table that looks more expensive than it is. Assembly was straightforward but definitely needs two people. The wood grain is beautiful and the finish is smooth. I'm taking off one star because it scratches a bit more easily than I'd like, but overall I'm happy with the purchase.\\n\\n- @woodworker_amy (Portland)\\n\"}\n"
     ]
    }
   ],
   "source": [
    "from helper import get_neo4j_import_dir\n",
    "print(get_neo4j_import_dir())\n",
    "from pathlib import Path\n",
    "class DummySession:\n",
    "    def __init__(self):\n",
    "        self.state = {}\n",
    "\n",
    "class DummyInvocationContext:\n",
    "    def __init__(self):\n",
    "        self.session = DummySession()\n",
    "\n",
    "tool_context = ToolContext(invocation_context=DummyInvocationContext())\n",
    "file_result = sample_file(\"product_reviews/gothenburg_table_reviews.md\", tool_context)\n",
    "print(file_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0d447d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_AGENT_NAME = \"ner_schema_agent_v1\"\n",
    "ner_schema_agent = Agent(\n",
    "    name=NER_AGENT_NAME,\n",
    "    description=\"Proposes the kind of named entities that could be extracted from text files.\",\n",
    "    model=llm,\n",
    "    instruction=ner_agent_instruction,\n",
    "    tools=ner_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca09ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_agent_initial_state = {\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"\"\"A multi-level bill of materials for manufactured products, useful for root cause analysis. \n",
    "        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.\"\"\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        \"product_reviews/gothenburg_table_reviews.md\",\n",
    "        \"product_reviews/helsingborg_dresser_reviews.md\",\n",
    "        \"product_reviews/jonkoping_coffee_table_reviews.md\",\n",
    "        \"product_reviews/linkoping_bed_reviews.md\",\n",
    "        \"product_reviews/malmo_desk_reviews.md\",\n",
    "        \"product_reviews/norrkoping_nightstand_reviews.md\",\n",
    "        \"product_reviews/orebro_lamp_reviews.md\",\n",
    "        \"product_reviews/stockholm_chair_reviews.md\",\n",
    "        \"product_reviews/uppsala_sofa_reviews.md\",\n",
    "        \"product_reviews/vasteras_bookshelf_reviews.md\"\n",
    "    ],\n",
    "    \"approved_construction_plan\": {\n",
    "        \"Product\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Product\",\n",
    "        },\n",
    "        \"Assembly\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Assembly\",\n",
    "        },\n",
    "        \"Part\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Part\",\n",
    "        },\n",
    "        \"Supplier\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Supplier\",\n",
    "        }\n",
    "        # Relationship construction omitted, since it won't get used in this notebook\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5085e9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Add product reviews to the knowledge graph to trace product complaints back through the manufacturing process.\n",
      "<<< Agent Response: I have proposed the following entity types to be extracted based on the approved user goal of conducting supply chain analysis through product reviews:\n",
      "\n",
      "### Entity Proposals:\n",
      "1. **Well-Known Entities**\n",
      "   - Product\n",
      "   - Supplier\n",
      "   - Part\n",
      "   - Assembly\n",
      "\n",
      "2. **Discovered Entities**\n",
      "   - Customer Feedback\n",
      "   - Issue Type\n",
      "   - Review Location\n",
      "\n",
      "These types will help in analyzing root causes of issues like quality control and assembly difficulty within the manufacturing process. Would you like to approve these proposed entities for extraction?\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location']}\n",
      "\n",
      "Proposed entities:  ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location']\n",
      "\n",
      "Awaiting approval.\n"
     ]
    }
   ],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "ner_agent_caller = await make_agent_caller(ner_schema_agent, ner_agent_initial_state)\n",
    "\n",
    "await ner_agent_caller.call(\"Add product reviews to the knowledge graph to trace product complaints back through the manufacturing process.\")\n",
    "\n",
    "# Alternatively, uncomment this line to get verbose output\n",
    "# await ner_agent_caller.call(\"Add product reviews.\", True)\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "if PROPOSED_ENTITIES in session_end.state:\n",
    "    print(\"\\nProposed entities: \", session_end.state[PROPOSED_ENTITIES])\n",
    "\n",
    "if APPROVED_ENTITIES in session_end.state:\n",
    "    print(\"\\nInappropriately approved entities: \", session_end.state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nAwaiting approval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd6e54b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Approve the proposed entities.\n",
      "<<< Agent Response: The proposed entity types have been successfully approved. These entities will be extracted to enhance your supply chain analysis by tracing product complaints back through the manufacturing process.\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location'], 'approved_entity_types': ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location']}\n",
      "\n",
      "Approved entities:  ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location']\n"
     ]
    }
   ],
   "source": [
    "await ner_agent_caller.call(\"Approve the proposed entities.\")\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "ner_end_state = session_end.state if session_end else {}\n",
    "\n",
    "print(\"Session state: \", ner_end_state)\n",
    "\n",
    "if APPROVED_ENTITIES in ner_end_state:\n",
    "    print(\"\\nApproved entities: \", ner_end_state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nStill awaiting approval? That is weird. Please check the agent's state and the proposed entities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "747b2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_role_and_goal = \"\"\"\n",
    "  You are a top-tier algorithm designed for analyzing text files and proposing\n",
    "  the type of facts that could be extracted from text that would be relevant \n",
    "  for a user's goal. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86896b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_hints = \"\"\"\n",
    "  Do not propose specific individual facts, but instead propose the general type \n",
    "  of facts that would be relevant for the user's goal. \n",
    "  For example, do not propose \"ABK likes coffee\" but the general type of fact \"Person likes Beverage\".\n",
    "  \n",
    "  Facts are triplets of (subject, predicate, object) where the subject and object are\n",
    "  approved entity types, and the proposed predicate provides information about\n",
    "  how they are related. For example, a fact type could be (Person, likes, Beverage).\n",
    "\n",
    "  Design rules for facts:\n",
    "  - only use approved entity types as subjects or objects. Do not propose new types of entities\n",
    "  - the proposed predicate should describe the relationship between the approved subject and object\n",
    "  - the predicate should optimize for information that is relevant to the user's goal\n",
    "  - the predicate must appear in the source text. Do not guess.\n",
    "  - use the 'add_proposed_fact' tool to record each proposed fact type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5eebcf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - use the 'get_approved_user_goal' tool to get the user goal\n",
    "    - use the 'get_approved_files' tool to get the list of approved files\n",
    "    - use the 'get_approved_entities' tool to get the list of approved entity types\n",
    "\n",
    "    Think step by step:\n",
    "    1. Use the 'get_approved_user_goal' tool to get the user goal\n",
    "    2. Sample some of the approved files using the 'sample_file' tool to understand the content\n",
    "    3. Consider how subjects and objects are related in the text\n",
    "    4. Call the 'add_proposed_fact' tool for each type of fact you propose\n",
    "    5. Use the 'get_proposed_facts' tool to retrieve all the proposed facts\n",
    "    6. Present the proposed types of facts to the user, along with an explanation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed2db59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_instruction = f\"\"\"\n",
    "{fact_agent_role_and_goal}\n",
    "{fact_agent_hints}\n",
    "{fact_agent_chain_of_thought_directions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24da478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPOSED_FACTS = \"proposed_fact_types\"\n",
    "APPROVED_FACTS = \"approved_fact_types\"\n",
    "\n",
    "def add_proposed_fact(approved_subject_label:str,\n",
    "                      proposed_predicate_label:str,\n",
    "                      approved_object_label:str,\n",
    "                      tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Add a proposed type of fact that could be extracted from the files.\n",
    "\n",
    "    A proposed fact type is a tuple of (subject, predicate, object) where\n",
    "    the subject and object are approved entity types and the predicate \n",
    "    is a proposed relationship label.\n",
    "\n",
    "    Args:\n",
    "      approved_subject_label: approved label of the subject entity type\n",
    "      proposed_predicate_label: label of the predicate\n",
    "      approved_object_label: approved label of the object entity type\n",
    "    \"\"\"\n",
    "    # Guard against invalid labels\n",
    "    approved_entities = tool_context.state.get(APPROVED_ENTITIES, [])\n",
    "    \n",
    "    if approved_subject_label not in approved_entities:\n",
    "        return tool_error(f\"Approved subject label {approved_subject_label} not found. Try again.\")\n",
    "    if approved_object_label not in approved_entities:\n",
    "        return tool_error(f\"Approved object label {approved_object_label} not found. Try again.\")\n",
    "    \n",
    "    current_predicates = tool_context.state.get(PROPOSED_FACTS, {})\n",
    "    current_predicates[proposed_predicate_label] = {\n",
    "        \"subject_label\": approved_subject_label,\n",
    "        \"predicate_label\": proposed_predicate_label,\n",
    "        \"object_label\": approved_object_label\n",
    "    }\n",
    "    tool_context.state[PROPOSED_FACTS] = current_predicates\n",
    "    return tool_success(PROPOSED_FACTS, current_predicates)\n",
    "    \n",
    "def get_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the proposed types of facts that could be extracted from the files.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_FACTS, {})\n",
    "\n",
    "\n",
    "def approve_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon user approval, records the proposed fact types as approved fact types\n",
    "\n",
    "    Only call this tool if the user has explicitly approved the proposed fact types.\n",
    "    \"\"\"\n",
    "    if PROPOSED_FACTS not in tool_context.state:\n",
    "        return tool_error(\"No proposed fact types to approve. Please set proposed facts first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_FACTS] = tool_context.state.get(PROPOSED_FACTS)\n",
    "    return tool_success(APPROVED_FACTS, tool_context.state[APPROVED_FACTS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca8d9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, \n",
    "    get_approved_entities,\n",
    "    sample_file,\n",
    "    add_proposed_fact,\n",
    "    get_proposed_facts,\n",
    "    approve_proposed_facts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4ba2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_AGENT_NAME = \"fact_type_extraction_agent_v1\"\n",
    "relevant_fact_agent = Agent(\n",
    "    name=FACT_AGENT_NAME,\n",
    "    description=\"Proposes the kind of relevant facts that could be extracted from text files.\",\n",
    "    model=llm,\n",
    "    instruction=fact_agent_instruction,\n",
    "    tools=fact_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d321ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Propose fact types that can be found in the text.\n",
      "<<< Agent Response: It seems I proposed some fact types using unapproved object labels. I'll adjust and share the valid proposed fact types based on the approved entities:\n",
      "\n",
      "Here are the refined proposed fact types based on the approved entity types that could be relevant for a supply chain analysis in the context of product reviews:\n",
      "\n",
      "1. **(Customer Feedback, mentions_issue, Issue Type)**\n",
      "   - Illustrates issues or complaints raised by customers about the product, which can help identify common problems or defects in manufacturing or design.\n",
      "\n",
      "2. **(Product, is_located_in, Review Location)**\n",
      "   - Highlights the geographical area from which the product reviews originate. This information could provide insights into regional variations in product perception or satisfaction.\n",
      "\n",
      "3. **(Product, has_assembly_feedback, Customer Feedback)**\n",
      "   - Includes customer comments related specifically to the assembly process. This type of feedback can reveal potential challenges or easy aspects of assembling the product.\n",
      "\n",
      "4. **(Product, has_feedback_on_quality, Customer Feedback)**\n",
      "   - Captures customer reviews related to the perceived quality of the product, including looks, durability, and material, providing valuable insights into the product's performance in real-world use.\n",
      "\n",
      "Please note that \"Rating\" and \"Time Duration\" were not recognized as approved entity types, thus I cannot propose facts involving them directly. Let me know if there's anything else I can do!\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location'], 'approved_entity_types': ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location'], 'proposed_fact_types': {'mentions_issue': {'subject_label': 'Customer Feedback', 'predicate_label': 'mentions_issue', 'object_label': 'Issue Type'}, 'is_located_in': {'subject_label': 'Product', 'predicate_label': 'is_located_in', 'object_label': 'Review Location'}, 'has_assembly_feedback': {'subject_label': 'Product', 'predicate_label': 'has_assembly_feedback', 'object_label': 'Customer Feedback'}, 'has_feedback_on_quality': {'subject_label': 'Product', 'predicate_label': 'has_feedback_on_quality', 'object_label': 'Customer Feedback'}}}\n",
      "\n",
      "Approved entities:  ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location']\n",
      "\n",
      "Correctly proposed facts:  {'mentions_issue': {'subject_label': 'Customer Feedback', 'predicate_label': 'mentions_issue', 'object_label': 'Issue Type'}, 'is_located_in': {'subject_label': 'Product', 'predicate_label': 'is_located_in', 'object_label': 'Review Location'}, 'has_assembly_feedback': {'subject_label': 'Product', 'predicate_label': 'has_assembly_feedback', 'object_label': 'Customer Feedback'}, 'has_feedback_on_quality': {'subject_label': 'Product', 'predicate_label': 'has_feedback_on_quality', 'object_label': 'Customer Feedback'}}\n",
      "\n",
      "Approved facts not found in session state, which is good.\n"
     ]
    }
   ],
   "source": [
    "# make a copy of the NER agent's end state to use as the initial state for the fact agent\n",
    "fact_agent_initial_state = ner_end_state.copy()\n",
    "\n",
    "fact_agent_caller = await make_agent_caller(relevant_fact_agent, fact_agent_initial_state)\n",
    "\n",
    "await fact_agent_caller.call(\"Propose fact types that can be found in the text.\")\n",
    "# await fact_agent_caller.call(\"Propose fact types that can be found in the text.\", True)\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "print(\"\\nApproved entities: \", session_end.state.get(APPROVED_ENTITIES, []))\n",
    "\n",
    "# Check that the agent proposed facts\n",
    "if PROPOSED_FACTS in session_end.state:\n",
    "    print(\"\\nCorrectly proposed facts: \", session_end.state[PROPOSED_FACTS])\n",
    "else:\n",
    "    print(\"\\nProposed facts not found in session state. What went wrong?\")\n",
    "\n",
    "# Check that the agent did not inappropriately approve facts\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nInappriately approved facts: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nApproved facts not found in session state, which is good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bb8e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Approve the proposed fact types.\n",
      "<<< Agent Response: The following proposed fact types have been approved:\n",
      "\n",
      "1. **(Customer Feedback, mentions_issue, Issue Type)**\n",
      "   - Highlights any issues raised by customers, aiding in identifying common product problems.\n",
      "\n",
      "2. **(Product, is_located_in, Review Location)**\n",
      "   - Indicates the geographical area from which product reviews are sourced, offering regional insights.\n",
      "\n",
      "3. **(Product, has_assembly_feedback, Customer Feedback)**\n",
      "   - Focuses on customer feedback regarding the assembly process, revealing potential challenges or ease in assembling.\n",
      "\n",
      "4. **(Product, has_feedback_on_quality, Customer Feedback)**\n",
      "   - Captures customer opinions on the product's quality, such as durability and material quality.\n",
      "\n",
      "These fact types will assist in constructing a detailed supply chain analysis based on product reviews. If you have further tasks or require additional information, feel free to let me know!\n",
      "Session state:  {'approved_user_goal': {'kind_of_graph': 'supply chain analysis', 'description': 'A multi-level bill of materials for manufactured products, useful for root cause analysis. \\n        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.'}, 'approved_files': ['product_reviews/gothenburg_table_reviews.md', 'product_reviews/helsingborg_dresser_reviews.md', 'product_reviews/jonkoping_coffee_table_reviews.md', 'product_reviews/linkoping_bed_reviews.md', 'product_reviews/malmo_desk_reviews.md', 'product_reviews/norrkoping_nightstand_reviews.md', 'product_reviews/orebro_lamp_reviews.md', 'product_reviews/stockholm_chair_reviews.md', 'product_reviews/uppsala_sofa_reviews.md', 'product_reviews/vasteras_bookshelf_reviews.md'], 'approved_construction_plan': {'Product': {'construction_type': 'node', 'label': 'Product'}, 'Assembly': {'construction_type': 'node', 'label': 'Assembly'}, 'Part': {'construction_type': 'node', 'label': 'Part'}, 'Supplier': {'construction_type': 'node', 'label': 'Supplier'}}, 'proposed_entity_types': ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location'], 'approved_entity_types': ['Product', 'Supplier', 'Part', 'Assembly', 'Customer Feedback', 'Issue Type', 'Review Location'], 'proposed_fact_types': {'mentions_issue': {'subject_label': 'Customer Feedback', 'predicate_label': 'mentions_issue', 'object_label': 'Issue Type'}, 'is_located_in': {'subject_label': 'Product', 'predicate_label': 'is_located_in', 'object_label': 'Review Location'}, 'has_assembly_feedback': {'subject_label': 'Product', 'predicate_label': 'has_assembly_feedback', 'object_label': 'Customer Feedback'}, 'has_feedback_on_quality': {'subject_label': 'Product', 'predicate_label': 'has_feedback_on_quality', 'object_label': 'Customer Feedback'}}, 'approved_fact_types': {'mentions_issue': {'subject_label': 'Customer Feedback', 'predicate_label': 'mentions_issue', 'object_label': 'Issue Type'}, 'is_located_in': {'subject_label': 'Product', 'predicate_label': 'is_located_in', 'object_label': 'Review Location'}, 'has_assembly_feedback': {'subject_label': 'Product', 'predicate_label': 'has_assembly_feedback', 'object_label': 'Customer Feedback'}, 'has_feedback_on_quality': {'subject_label': 'Product', 'predicate_label': 'has_feedback_on_quality', 'object_label': 'Customer Feedback'}}}\n",
      "\n",
      "Approved fact types:  {'mentions_issue': {'subject_label': 'Customer Feedback', 'predicate_label': 'mentions_issue', 'object_label': 'Issue Type'}, 'is_located_in': {'subject_label': 'Product', 'predicate_label': 'is_located_in', 'object_label': 'Review Location'}, 'has_assembly_feedback': {'subject_label': 'Product', 'predicate_label': 'has_assembly_feedback', 'object_label': 'Customer Feedback'}, 'has_feedback_on_quality': {'subject_label': 'Product', 'predicate_label': 'has_feedback_on_quality', 'object_label': 'Customer Feedback'}}\n"
     ]
    }
   ],
   "source": [
    "await fact_agent_caller.call(\"Approve the proposed fact types.\")\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nApproved fact types: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nFailed to approve fact types.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430588ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334cecb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-graph-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
